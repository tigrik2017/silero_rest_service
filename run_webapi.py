
# ----------

from fastapi import FastAPI, HTTPException, Query
from starlette.responses import Response
from enum import Enum
import uvicorn
import multiprocessing
import torch

app = FastAPI()

version = "1.0"

class ModelName(str, Enum):
    v4ru = "v4_ru.pt"
    v31ru = "v3_1_ru.pt"

class SampleRate(str, Enum):
    bit8000 = 8000,
    bit24000 = 24000,
    bit48000 = 48000
    
class Speakrs(str, Enum):
    aidar = "aidar"
    baya = "baya"
    kseniya = "kseniya"
    xenia = "xenia"
    eugene = "eugene"
    random = "random"

_device = torch.device('cpu')
_model = None
_currentModel = None

def load_model(model_name: ModelName):
    global _model, _device, _currentModel
    if _currentModel != model_name:
        _currentModel = model_name
        modelurl = 'https://models.silero.ai/models/tts/ru/' + model_name.value

        import os
        torch.set_num_threads(1)
        local_file = model_name.value

        if not os.path.isfile(local_file):
            print("Downloading Silero model...")
            torch.hub.download_url_to_file(modelurl, local_file)

        _model = torch.package.PackageImporter(local_file).load_pickle("tts_models", "model")
        _model.to(_device)
        print(f"Model {model_name} loaded")


@app.on_event("startup")
async def startup_event():
    load_model(ModelName.v4ru)


@app.get(
    "/getwav",

    # Set what the media type will be in the autogenerated OpenAPI specification.
    # fastapi.tiangolo.com/advanced/additional-responses/#additional-media-types-for-the-main-response
    responses = {
        200: {
            "content": {"audio/wav": {}}
        }
    },

    # Prevent FastAPI from adding "application/json" as an additional
    # response media type in the autogenerated OpenAPI specification.
    # https://github.com/tiangolo/fastapi/issues/3258
    response_class=Response
)
async def getwav(
    text_to_speech: str = Query(..., description="Текст для озвучки"), #обязательный параметр
    model_name: ModelName = Query(..., description="Выбор модели"),
    speaker: Speakrs = Query(default=Speakrs.xenia, description="Спикеры"),
    sample_rate: SampleRate = Query(default=SampleRate.bit24000, description="Выходной битрейт"),
    put_accent: bool = Query(default=True, description="Простановка акцентов в тексте"),
    put_yo: bool = Query(default=True, description="Простановка 'ё' в тексте")
):
    """
       Return WAV file with rendered text\n
       :param str text_to_speech: Текст для озвучки\n
       :param str speaker: One of speakers name\n
       :param int sample_rate: Sample rate to generation\n
       :param int put_accent: 1/0, 1 - простановка акцентов в тексте\n
       :param int put_yo: 1/0, 1 - простановка Ё в тексте\n
       :return: WAV file
    """
    
    if (model_name != _currentModel):
        load_model(model_name)
    
    import os

    wavfile = "temp.wav"
    path = _model.save_wav(
        text=text_to_speech,
        speaker=speaker.value,
        put_accent=(put_accent==1),
        put_yo=( put_yo==1),
        sample_rate=sample_rate.value
    )

    # перемещаем wav на новое место
    # if os.path.exists(wavfile):
    #     os.unlink(wavfile)
    # os.rename(path, wavfile)

    in_file = open(path, "rb") # opening for [r]eading as [b]inary
    data = in_file.read() # if you only wanted to read 512 bytes, do .read(512)
    in_file.close()

    return Response(content=data, media_type="audio/wav")



if __name__ == "__main__":
    multiprocessing.freeze_support()
    print("Running silero_rest_service server v{0}...".format(version))
    uvicorn.run("run_webapi:app", host="0.0.0.0", port=5010, log_level="info")